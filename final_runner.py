import os
import json
from datetime import datetime

# ----- Forensic score imports (existing, untouched) -----
from scoring.ela_score import compute_ela_score
from scoring.noise_score import compute_noise_score
from scoring.compression_score import compute_compression_score
from scoring.metadata_score import compute_metadata_score
from scoring.font_alignment_score import compute_font_alignment_score
from scoring.final_score import compute_final_score

# ----- ML prediction -----
from ml.predict_xgb import predict_risk


def run_final_scoring(
    pdf_path: str,
    forensics_output_dir: str,
    pdf_metadata: dict
) -> dict:
    """
    Final scoring pipeline:
    - Uses forensic outputs generated by SourceCode
    - Computes individual forensic scores
    - Combines with ML (XGBoost)
    - Saves final JSON report
    """

    # -----------------------------
    # Resolve forensic image paths
    # -----------------------------
    ela_image = os.path.join(forensics_output_dir, "ELA", "page-1.jpg")
    noise_image = os.path.join(forensics_output_dir, "Noise", "page-1.jpg")
    compression_image = os.path.join(forensics_output_dir, "Compression", "page-1.jpg")
    font_alignment_image = os.path.join(forensics_output_dir, "Font_Alignment", "page-1.jpg")

    # -----------------------------
    # Individual forensic scores (0–1)
    # -----------------------------
    ela_score = compute_ela_score(ela_image)
    noise_score = compute_noise_score(noise_image)
    compression_score = compute_compression_score(compression_image)
    metadata_score = compute_metadata_score(pdf_metadata)
    font_score = compute_font_alignment_score(font_alignment_image)

    # -----------------------------
    # Rule-based forensic aggregation
    # -----------------------------
    forensic_result = compute_final_score(
        ela_score=ela_score,
        noise_score=noise_score,
        compression_score=compression_score,
        metadata_score=metadata_score,
        font_score=font_score
    )

    # forensic_result["risk_score"] → percentage (0–100)

    # -----------------------------
    # ML prediction (XGBoost)
    # -----------------------------
    ml_features = {
        "ela_score": ela_score,
        "noise_score": noise_score,
        "compression_score": compression_score,
        # CNN placeholders (demo-safe)
        "cnn_f1": 0.5,
        "cnn_f2": 0.5
    }

    ml_output = predict_risk(ml_features)
    ml_probability = ml_output["ml_probability"]   # 0–1

    # -----------------------------
    # Hybrid final risk score
    # -----------------------------
    hybrid_risk = round(
        0.6 * forensic_result["risk_score"] +
        0.4 * (ml_probability * 100),
        2
    )

    verdict = "Manipulated" if hybrid_risk >= 50 else "Clean"

    # -----------------------------
    # Final result object
    # -----------------------------
    final_result = {
        "risk_score": forensic_result["risk_score"],
        "ml_probability": round(ml_probability, 3),
        "hybrid_risk": hybrid_risk,
        "verdict": verdict,

        "forensic_breakdown": {
            "ela_score": round(ela_score, 3),
            "noise_score": round(noise_score, 3),
            "compression_score": round(compression_score, 3),
            "metadata_score": round(metadata_score, 3),
            "font_alignment_score": round(font_score, 3)
        },

        "traceability": {
            "pdf_path": pdf_path,
            "forensics_output_dir": forensics_output_dir,
            "timestamp": datetime.utcnow().isoformat()
        }
    }

    # -----------------------------
    # Save report
    # -----------------------------
    reports_dir = os.path.join(os.getcwd(), "reports")
    os.makedirs(reports_dir, exist_ok=True)

    report_name = f"id_final_report_{int(datetime.utcnow().timestamp())}.json"
    report_path = os.path.join(reports_dir, report_name)

    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(final_result, f, indent=4)

    final_result["report_path"] = report_path

    return final_result